!pip install captum

# === Imports ===
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import numpy as np
from captum.attr import IntegratedGradients
from captum.attr import visualization as viz
import warnings
warnings.filterwarnings("ignore")

# === Configuration ===
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_CLASSES = 4
BATCH_SIZE = 32
EPOCHS_SUP = 50
LR = 1e-4
class_names = ['Cyst', 'Normal', 'Stone', 'Tumor']

# === Transforms ===
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # For grayscale CT
])

# === Dataset ===
dataset = datasets.ImageFolder(
    root='/kaggle/input/vitdinov2/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone',
    transform=transform
)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# === DINOv2 Backbone ===
def get_dinov2_backbone():
    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')
    return model

# === MLP Classifier (Fine-tuned) ===
class MLPClassifier(nn.Module):
    def __init__(self, backbone):
        super().__init__()
        self.backbone = backbone
        self.head = nn.Sequential(
            nn.Linear(768, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, NUM_CLASSES)
        )

    def forward(self, x):
        with torch.set_grad_enabled(self.backbone.training):
            features = self.backbone.forward_features(x)
            x = features["x_norm_clstoken"]  # Extract the tensor from dict output
        return self.head(x)

# === Supervised Training ===
def train_supervised(model, train_loader, val_loader, epochs):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
    best_acc, best_model = 0.0, None
    train_losses, val_losses = [], []

    for epoch in range(epochs):
        model.train()
        total_loss, correct, total = 0, 0, 0

        for x, y in train_loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            out = model(x)
            loss = criterion(out, y)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            pred = out.argmax(1)
            correct += (pred == y).sum().item()
            total += y.size(0)

        train_acc = correct / total
        train_losses.append(total_loss / len(train_loader))

        # Validation
        model.eval()
        val_loss, correct, total = 0, 0, 0
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                out = model(x)
                loss = criterion(out, y)
                val_loss += loss.item()
                pred = out.argmax(1)
                correct += (pred == y).sum().item()
                total += y.size(0)

        val_acc = correct / total
        val_losses.append(val_loss / len(val_loader))

        if val_acc > best_acc:
            best_acc = val_acc
            best_model = model.state_dict()
            torch.save(best_model, "best_model.pth")

        print(f"[Epoch {epoch+1}/{epochs}] Train Loss: {train_losses[-1]:.4f}, Val Acc: {val_acc:.4f}")

    return train_losses, val_losses

# === Evaluation ===
def evaluate(model, loader):
    model.eval()
    preds, labels = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(DEVICE)
            out = model(x).argmax(1)
            preds += out.cpu().tolist()
            labels += y.tolist()

    print("\n=== Final Classification Report ===")
    print(classification_report(labels, preds, target_names=class_names))

# === Integrated Gradients ===
def generate_integrated_gradients(model, input_image, target_class):
    integrated_gradients = IntegratedGradients(model)
    attributions, delta = integrated_gradients.attribute(input_image, target=target_class, return_convergence_delta=True)
    return attributions

def visualize_integrated_gradients(attributions, input_image):
    viz.visualize_image_attr(attributions.squeeze().cpu().numpy(), input_image.squeeze().cpu().numpy(),
                             method="heat_map", cmap="jet", show_colorbar=True)

# === MAIN ===
if __name__ == "__main__":
    print("Loading pretrained DINOv2 backbone...")
    backbone = get_dinov2_backbone().to(DEVICE)

    for param in backbone.parameters():
        param.requires_grad = True

    model = MLPClassifier(backbone).to(DEVICE)

    print("Starting supervised fine-tuning...")
    train_losses, val_losses = train_supervised(model, train_loader, val_loader, epochs=EPOCHS_SUP)

    print("Evaluating best model...")
    model.load_state_dict(torch.load("best_model.pth"))
    evaluate(model, val_loader)

    # === Loss Curves ===
    plt.figure(figsize=(12, 5))
    plt.plot(range(1, EPOCHS_SUP + 1), train_losses, label='Train Loss')
    plt.plot(range(1, EPOCHS_SUP + 1), val_losses, label='Validation Loss')
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # === Visualization ===
    print("Generating Integrated Gradients visualization...")
    try:
        sample_batch = next(iter(val_loader))
        sample_image = sample_batch[0][:1].to(DEVICE)

        model.eval()
        with torch.no_grad():
            output = model(sample_image)
            target_class = torch.argmax(output, dim=1).item()

        print(f"Predicted class: {class_names[target_class]}")

        attributions = generate_integrated_gradients(model, sample_image, target_class)
        visualize_integrated_gradients(attributions, sample_image)

    except Exception as e:
        print(f"Error in visualization: {e}")
Loading pretrained DINOv2 backbone...
Downloading: "https://github.com/facebookresearch/dinov2/zipball/main" to /root/.cache/torch/hub/main.zip
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth
100%|██████████| 330M/330M [00:01<00:00, 234MB/s] 
Starting supervised fine-tuning...
[Epoch 1/50] Train Loss: 0.9223, Val Acc: 0.6715
[Epoch 2/50] Train Loss: 0.7460, Val Acc: 0.6976
[Epoch 3/50] Train Loss: 0.5820, Val Acc: 0.8088
[Epoch 4/50] Train Loss: 0.4273, Val Acc: 0.8598
[Epoch 5/50] Train Loss: 0.2696, Val Acc: 0.9418
[Epoch 6/50] Train Loss: 0.1771, Val Acc: 0.9333
[Epoch 7/50] Train Loss: 0.1054, Val Acc: 0.9534
[Epoch 8/50] Train Loss: 0.0945, Val Acc: 0.7004
[Epoch 9/50] Train Loss: 0.1426, Val Acc: 0.8811
[Epoch 10/50] Train Loss: 0.0633, Val Acc: 0.9932
[Epoch 11/50] Train Loss: 0.0579, Val Acc: 0.9799
[Epoch 12/50] Train Loss: 0.0478, Val Acc: 0.9884
[Epoch 13/50] Train Loss: 0.0350, Val Acc: 0.9241
[Epoch 14/50] Train Loss: 0.0470, Val Acc: 0.9867
[Epoch 15/50] Train Loss: 0.0296, Val Acc: 0.9952
[Epoch 16/50] Train Loss: 0.0243, Val Acc: 0.9855
[Epoch 17/50] Train Loss: 0.0413, Val Acc: 0.9924
[Epoch 18/50] Train Loss: 0.0489, Val Acc: 0.9478
[Epoch 19/50] Train Loss: 0.0336, Val Acc: 0.9956
[Epoch 20/50] Train Loss: 0.0354, Val Acc: 0.9912
[Epoch 21/50] Train Loss: 0.0178, Val Acc: 0.9932
[Epoch 22/50] Train Loss: 0.0229, Val Acc: 0.9892
[Epoch 23/50] Train Loss: 0.0463, Val Acc: 0.9839
[Epoch 24/50] Train Loss: 0.0258, Val Acc: 0.9916
[Epoch 25/50] Train Loss: 0.0173, Val Acc: 0.9912
[Epoch 26/50] Train Loss: 0.0203, Val Acc: 0.9928
[Epoch 27/50] Train Loss: 0.0284, Val Acc: 0.9940
[Epoch 28/50] Train Loss: 0.0199, Val Acc: 0.9900
[Epoch 29/50] Train Loss: 0.0189, Val Acc: 0.9960
[Epoch 30/50] Train Loss: 0.0035, Val Acc: 0.9960
[Epoch 31/50] Train Loss: 0.0257, Val Acc: 0.9831
[Epoch 32/50] Train Loss: 0.0201, Val Acc: 0.9807
[Epoch 33/50] Train Loss: 0.0199, Val Acc: 0.9980
[Epoch 34/50] Train Loss: 0.0129, Val Acc: 0.9827
[Epoch 35/50] Train Loss: 0.0256, Val Acc: 0.9948
[Epoch 36/50] Train Loss: 0.0155, Val Acc: 0.9964
[Epoch 37/50] Train Loss: 0.0122, Val Acc: 0.9968
[Epoch 38/50] Train Loss: 0.0147, Val Acc: 0.9920
[Epoch 39/50] Train Loss: 0.0147, Val Acc: 0.9884
[Epoch 40/50] Train Loss: 0.0256, Val Acc: 0.9859
[Epoch 41/50] Train Loss: 0.0241, Val Acc: 0.9964
[Epoch 42/50] Train Loss: 0.0005, Val Acc: 0.9960
[Epoch 43/50] Train Loss: 0.0142, Val Acc: 0.9936
[Epoch 44/50] Train Loss: 0.0084, Val Acc: 0.9976
[Epoch 45/50] Train Loss: 0.0241, Val Acc: 0.9928
[Epoch 46/50] Train Loss: 0.0187, Val Acc: 0.9956
[Epoch 47/50] Train Loss: 0.0105, Val Acc: 0.9948
[Epoch 48/50] Train Loss: 0.0063, Val Acc: 0.9968
[Epoch 49/50] Train Loss: 0.0164, Val Acc: 0.9896
[Epoch 50/50] Train Loss: 0.0283, Val Acc: 0.9908
Evaluating best model...

=== Final Classification Report ===
              precision    recall  f1-score   support

        Cyst       1.00      1.00      1.00       732
      Normal       1.00      1.00      1.00      1022
       Stone       1.00      0.99      0.99       278
       Tumor       1.00      1.00      1.00       458

    accuracy                           1.00      2490
   macro avg       1.00      1.00      1.00      2490
weighted avg       1.00      1.00      1.00      2490


Generating Integrated Gradients visualization...
Predicted class: Tumor
Error in visualization: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
